{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "get_ipython().system('{sys.executable} -m pip install keras')\n",
    "get_ipython().system('{sys.executable} -m pip install pillow')\n",
    "get_ipython().system('{sys.executable} -m pip install tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "continental-repository",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "logical-secondary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sublime-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.2984 - accuracy: 0.9135 - val_loss: 0.0961 - val_accuracy: 0.9762\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 56s 118ms/step - loss: 0.0579 - accuracy: 0.9843 - val_loss: 0.0544 - val_accuracy: 0.9841\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 53s 114ms/step - loss: 0.0340 - accuracy: 0.9913 - val_loss: 0.0460 - val_accuracy: 0.9848\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 50s 108ms/step - loss: 0.0224 - accuracy: 0.9946 - val_loss: 0.0431 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 52s 110ms/step - loss: 0.0158 - accuracy: 0.9967 - val_loss: 0.0439 - val_accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 52s 112ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.0412 - val_accuracy: 0.9871\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 52s 110ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 0.0419 - val_accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 51s 109ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.0419 - val_accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 51s 109ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.0422 - val_accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 50s 106ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0413 - val_accuracy: 0.9872\n",
      "The model has successfully trained\n",
      "Saving the model as mnist.h5\n",
      "> 4.3170e-02 98.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justina32\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.98      0.99      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.99      0.99      1028\n",
      "           8       0.99      0.99      0.99       974\n",
      "           9       0.99      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization\n",
    "class MNIST_CNN(object):\n",
    "    def __init__(self):\n",
    "        self.load_mnist()\n",
    "\n",
    "        # prepare pixel data\n",
    "        self.trainX, self.testX = self.prep_pixels(self.trainX, self.testX)\n",
    "\n",
    "    def load_mnist(self):\n",
    "        \"\"\"\n",
    "        load train and test dataset\n",
    "        \"\"\"\n",
    "        # load dataset\n",
    "        (self.trainX, self.trainY), (self.testX, self.testY0) = mnist.load_data()\n",
    "\n",
    "        # reshape dataset to have a single channel\n",
    "        self.trainX = self.trainX.reshape((self.trainX.shape[0], 28, 28, 1))\n",
    "\n",
    "        self.testX = self.testX.reshape((self.testX.shape[0], 28, 28, 1))\n",
    "\n",
    "        # one hot encode target values\n",
    "        self.trainY = to_categorical(self.trainY)\n",
    "        self.testY = to_categorical(self.testY0)\n",
    "\n",
    "    def prep_pixels(self, train_set, test_set):\n",
    "        \"\"\"\n",
    "        Scale pixels\n",
    "        :param train_set:\n",
    "        :param test_set:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # convert from integers to floats\n",
    "        train_norm = train_set.astype('float32')\n",
    "        test_norm = test_set.astype('float32')\n",
    "\n",
    "        # normalize to range 0-1\n",
    "        train_norm = train_norm / 255.0\n",
    "        test_norm = test_norm / 255.0\n",
    "\n",
    "        # return normalized images\n",
    "        return train_norm, test_norm\n",
    "\n",
    "    def define_model(self):\n",
    "        \"\"\"\n",
    "        define cnn model\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "        model.add(BatchNormalization())     # Improvement to Learning\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())     # Improvement to Learning\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        # compile model\n",
    "        opt = SGD(lr=0.01, momentum=0.9)\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "        print(\"The model has successfully trained\")\n",
    "        model.save('mnist.h5')\n",
    "        print(\"Saving the model as mnist.h5\")\n",
    "        return model\n",
    "\n",
    "    def train(self, epochs=10):\n",
    "        # define model\n",
    "        model = self.define_model()\n",
    "\n",
    "        # fit model\n",
    "        history = model.fit(self.trainX, self.trainY,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=32,\n",
    "                            validation_data=(self.testX, self.testY),\n",
    "                            verbose=0)\n",
    "\n",
    "        # evaluate model\n",
    "        loss, acc = model.evaluate(self.testX, self.testY, verbose=0)\n",
    "        print('> %.4e %.3f' % (loss, acc * 100.0))\n",
    "\n",
    "        #y_prob = model.predict(self.testX, batch_size=1)\n",
    "        #print(y_prob)\n",
    "\n",
    "        y_pred = model.predict_classes(self.testX, batch_size=1)\n",
    "        #print(y_pred)\n",
    "\n",
    "        #print(self.testY0)\n",
    "        self.performance(self.testY0, y_pred)\n",
    "\n",
    "    def performance(self, y_test, y_predict):\n",
    "        from sklearn.metrics import classification_report, confusion_matrix\n",
    "        import pandas as pd\n",
    "\n",
    "        report = classification_report(y_test, y_predict)\n",
    "        print(report)\n",
    "\n",
    "\n",
    "def test():\n",
    "    # CNN\n",
    "    prj = MNIST_CNN()\n",
    "    prj.train(epochs=5)   \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()\n",
    "\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "developing-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "model = load_model('prj_cnn.h5')\n",
    "def predict_digit(img):\n",
    "    #resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1,28,28,1)\n",
    "    img = img/255.0\n",
    "    #predicting the class\n",
    "    res = model.predict([img])[0]\n",
    "    return np.argmax(res), max(res)\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "        digit, acc = predict_digit(im)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "app = App()\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-passion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-playback",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
